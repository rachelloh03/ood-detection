{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41595bd3",
   "metadata": {},
   "source": [
    "# OOD Detection Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc7a721",
   "metadata": {},
   "source": [
    "## 1. Load data to obtain hidden representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76152ddf",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8ed17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants.data_constants import JORDAN_DATASET_FILEPATH, MAESTRO_DATASET_FILEPATH\n",
    "from data.jordan_dataset import JordanDataset\n",
    "from data.maestro_dataset import MaestroDataset\n",
    "\n",
    "\n",
    "print(\"Loading Jordan dataset - train\")\n",
    "id_train_base_dataset = JordanDataset(\n",
    "    data_dir=JORDAN_DATASET_FILEPATH,\n",
    "    split=\"train\",\n",
    "    name=\"id_train_base_dataset\"\n",
    ")\n",
    "print(f\"Obtained {len(id_train_base_dataset)} training examples from Jordan dataset - train\")\n",
    "\n",
    "print(\"Loading Jordan dataset - test\")\n",
    "id_test_base_dataset = JordanDataset(\n",
    "    data_dir=JORDAN_DATASET_FILEPATH,\n",
    "    split=\"validation\",\n",
    "    name=\"id_test_base_dataset\",\n",
    "    num_samples=80\n",
    ")\n",
    "print(f\"Obtained {len(id_test_base_dataset)} testing examples from Jordan dataset - test\")\n",
    "\n",
    "print(\"Loading Maestro dataset - test\")\n",
    "ood_base_dataset = MaestroDataset(\n",
    "    data_dir=MAESTRO_DATASET_FILEPATH,\n",
    "    split=\"test\",\n",
    "    name=\"maestro_test_base_dataset\",\n",
    "    num_samples=80\n",
    ")\n",
    "print(f\"Obtained {len(ood_base_dataset)} testing examples from Maestro dataset - test\")\n",
    "\n",
    "print(\"Example id_train_base_dataset[100]\", id_train_base_dataset[100][\"input_ids\"][:10])\n",
    "print(\"Example id_test_base_dataset[100]\", id_test_base_dataset[50][\"input_ids\"][:10])\n",
    "print(\"Example ood_base_dataset[100]\", ood_base_dataset[50][\"input_ids\"][:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4505700",
   "metadata": {},
   "source": [
    "From each data sample in each of these datasets, extract all sliding windows of length SLIDING_WINDOW_LEN = 120 tokens (=40 events). This can be configured in constants/real_time_constants.py. The stride being STRIDE = 3 corresponds to moving the window by 3 tokens (=1 event) at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96062e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants.real_time_constants import SLIDING_WINDOW_LEN, STRIDE\n",
    "from data.sliding_window import SlidingWindowDataset\n",
    "\n",
    "\n",
    "id_train_dataset = SlidingWindowDataset(id_train_base_dataset, name=\"id_train_dataset\", k=SLIDING_WINDOW_LEN, stride=STRIDE)\n",
    "id_test_dataset = SlidingWindowDataset(id_test_base_dataset, name=\"id_test_dataset\", k=SLIDING_WINDOW_LEN, stride=STRIDE, num_samples=200)\n",
    "ood_dataset = SlidingWindowDataset(ood_base_dataset, name=\"ood_dataset\", k=SLIDING_WINDOW_LEN, stride=STRIDE, num_samples=200)\n",
    "\n",
    "print(\"len(id_train_dataset)\", len(id_train_dataset))\n",
    "print(\"len(id_test_dataset)\", len(id_test_dataset))\n",
    "print(\"len(ood_dataset)\", len(ood_dataset))\n",
    "\n",
    "print(\"Example id_train_dataset[100]\", id_train_dataset[100][\"input_ids\"][:10])\n",
    "print(\"Example id_test_dataset[100]\", id_test_dataset[100][\"input_ids\"][:50])\n",
    "print(\"Example ood_dataset[100]\", ood_dataset[100][\"input_ids\"][:50])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d75f5e",
   "metadata": {},
   "source": [
    "### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad9be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from utils.data_loading import collate_fn\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "id_train_dataloader = DataLoader(id_train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "id_test_dataloader = DataLoader(id_test_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "ood_dataloader = DataLoader(ood_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56cff5",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f594f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants.model_constants import DEVICE, JORDAN_MODEL_NAME\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    JORDAN_MODEL_NAME,\n",
    "    dtype=torch.float32,\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d56075",
   "metadata": {},
   "source": [
    "# 2. OOD Detector\n",
    "\n",
    "Refer to [OOD detection docs](../../docs/ood_detection.md) for more information about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b2b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main.transformation_functions import extract_layer_transformation, GaussianMixtureWithScore\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from main.transformations import Transformations\n",
    "from main.scoring_functions import identity\n",
    "from extract_layers.pooling_functions import pool_mean_std\n",
    "\n",
    "transformations = Transformations(\n",
    "    [\n",
    "        extract_layer_transformation(model, pool_mean_std, [17]),\n",
    "        PCA(n_components=100),\n",
    "        StandardScaler(),\n",
    "        GaussianMixtureWithScore(\n",
    "            n_components=4,\n",
    "            dim=100,\n",
    "            diagonal_cov=False,\n",
    "        ), # fits a GMM with 4 components to the data, with full covariance matrix, then returns the negative log density.\n",
    "    ]\n",
    ")\n",
    "scoring_function = identity # above transformations already return a score, no further scoring needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e4470",
   "metadata": {},
   "source": [
    "## Create OOD detector\n",
    "from transformations and scoring function. Takes about 1 minute with STRIDE=30, lower STRIDE means longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf0f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main.ood_detector import OODDetector\n",
    "\n",
    "ood_detector = OODDetector(\n",
    "    embedding_function=transformations,\n",
    "    scoring_function=scoring_function,\n",
    "    id_train_data=id_train_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3154d9",
   "metadata": {},
   "source": [
    "We can evaluate the detector!\n",
    "\n",
    "```threshold = 0.7``` with ```threshold_type = \"percentile\"``` means that the score threshold is set to be the 70th percentile of all the scores (ID test + OOD test combined)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92690a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix, true_positive_rate, false_positive_rate = ood_detector.evaluate(\n",
    "    id_test_dataloader,\n",
    "    ood_dataloader,\n",
    "    threshold=0.5,\n",
    "    threshold_type=\"percentile\",\n",
    ")\n",
    "print(\"Confusion matrix:\", confusion_matrix)\n",
    "print(\"True positive rate:\", true_positive_rate)\n",
    "print(\"False positive rate:\", false_positive_rate)\n",
    "\n",
    "f1_score = 2 * (true_positive_rate * false_positive_rate) / (true_positive_rate + false_positive_rate)\n",
    "\n",
    "print(\"F1 score:\", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98be091",
   "metadata": {},
   "source": [
    "We can plot the ROC curve and get AUROC!\n",
    "\n",
    "AUROC will appear as ```main/auroc.png```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506504ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b92b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.auroc import get_auroc\n",
    "\n",
    "auroc = get_auroc(\n",
    "    ood_detector,\n",
    "    id_test_dataloader,\n",
    "    ood_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUROC:\", auroc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c582ba",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Hover above the bars to see the sample IDs corresponding to the scores. In the next cell, you can input the IDs to hear what the samples sound like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce21c4b",
   "metadata": {},
   "source": [
    "First make sure that the dataset shuffling is fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66daf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_test_samples = torch.cat([batch[\"input_ids\"] for batch in id_test_dataloader]).to(DEVICE)\n",
    "ood_samples = torch.cat([batch[\"input_ids\"] for batch in ood_dataloader]).to(DEVICE)\n",
    "\n",
    "print(\"ID test samples:\", id_test_samples.shape)\n",
    "print(\"OOD samples:\", ood_samples.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec7dd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by scores\n",
    "id_test_samples = id_test_samples[torch.argsort(ood_detector.score(id_test_samples))]\n",
    "ood_samples = ood_samples[torch.argsort(ood_detector.score(ood_samples))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986b9a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.graph_viz import get_graph_visualization\n",
    "\n",
    "fig = get_graph_visualization(\n",
    "    ood_detector,\n",
    "    id_test_samples,\n",
    "    ood_samples,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5691450c",
   "metadata": {},
   "source": [
    "### Note: clear outputs for below cell if you run it before saving otherwise it will hang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9897412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.audio_grid import create_audio_grid\n",
    "\n",
    "create_audio_grid(id_test_samples, max_samples=24, indices=[0, 5, 10, 15, 25, 35, 55, 75, 95, 115, 135, 155, 175, 180, 185, 190, 193, 194, 195, 196, 197, 198, 199, 200], cols=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46483e4c",
   "metadata": {},
   "source": [
    "Hear individual ID input samples and outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99dea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_input_index = 190\n",
    "ood_input_index = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d2c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils.convert import sequence_to_wav\n",
    "from IPython.display import Audio\n",
    "\n",
    "id_input_sample = id_test_samples[id_input_index].unsqueeze(0).to(DEVICE)\n",
    "id_sequence = id_input_sample[0].tolist()\n",
    "print(\"ID sequence (first 50 tokens):\", id_sequence[:50])\n",
    "print(\"OOD score for ID sequence\", ood_detector.score(id_input_sample).item())\n",
    "id_export_filepath = \"id_input_sample.wav\"\n",
    "if os.path.exists(id_export_filepath):\n",
    "    os.remove(id_export_filepath)\n",
    "sequence_to_wav(id_sequence, id_export_filepath)\n",
    "\n",
    "\n",
    "\n",
    "Audio(id_export_filepath)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3278b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_input_sample = ood_samples[ood_input_index].unsqueeze(0).to(DEVICE)\n",
    "ood_sequence = ood_input_sample[0].tolist()\n",
    "print(\"OOD sequence (first 50 tokens):\", ood_sequence[:50])\n",
    "print(\"OOD score for OOD sequence\", ood_detector.score(ood_input_sample).item())\n",
    "ood_export_filepath = \"ood_input_sample.wav\"\n",
    "sequence_to_wav(ood_sequence, ood_export_filepath)\n",
    "\n",
    "Audio(ood_export_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9da4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sample import generate_tokens\n",
    "from constants.token_constants import AR\n",
    "\n",
    "generate_length = 120\n",
    "\n",
    "id_output_sample = generate_tokens(\n",
    "    model,\n",
    "    [AR],\n",
    "    id_sequence[1:],\n",
    "    generate_length,\n",
    ")\n",
    "\n",
    "print(\"input\", id_sequence[:50])\n",
    "input_len = len(id_sequence) - 1\n",
    "print(\"output\", id_output_sample[input_len:input_len+50])\n",
    "\n",
    "id_export_filepath = \"id_output_sample.wav\"\n",
    "sequence_to_wav(id_output_sample, id_export_filepath)\n",
    "\n",
    "Audio(id_export_filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21821180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ood-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
