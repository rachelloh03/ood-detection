{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41595bd3",
   "metadata": {},
   "source": [
    "# OOD Detection Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc7a721",
   "metadata": {},
   "source": [
    "## 1. Load data to obtain hidden representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76152ddf",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c8ed17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/scratch/joeltjy1/conda_envs/ood-detection/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Jordan dataset - train\n",
      "Detected 0 bad samples\n",
      "Obtained 4550 training examples from Jordan dataset - train\n",
      "Loading Jordan dataset - test\n",
      "Detected 0 bad samples\n",
      "Obtained 80 testing examples from Jordan dataset - test\n",
      "Loading Maestro dataset - test\n",
      "Obtained 80 testing examples from Maestro dataset - test\n"
     ]
    }
   ],
   "source": [
    "from constants.data_constants import JORDAN_DATASET_FILEPATH, MAESTRO_DATASET_FILEPATH\n",
    "from data.jordan_dataset import JordanDataset\n",
    "from data.maestro_dataset import MaestroDataset\n",
    "\n",
    "\n",
    "print(\"Loading Jordan dataset - train\")\n",
    "id_train_base_dataset = JordanDataset(\n",
    "    data_dir=JORDAN_DATASET_FILEPATH,\n",
    "    split=\"train\",\n",
    "    name=\"id_train_base_dataset\"\n",
    ")\n",
    "print(f\"Obtained {len(id_train_base_dataset)} training examples from Jordan dataset - train\")\n",
    "\n",
    "print(\"Loading Jordan dataset - test\")\n",
    "id_test_base_dataset = JordanDataset(\n",
    "    data_dir=JORDAN_DATASET_FILEPATH,\n",
    "    split=\"validation\",\n",
    "    name=\"id_test_base_dataset\",\n",
    "    num_samples=80\n",
    ")\n",
    "print(f\"Obtained {len(id_test_base_dataset)} testing examples from Jordan dataset - test\")\n",
    "\n",
    "print(\"Loading Maestro dataset - test\")\n",
    "ood_base_dataset = MaestroDataset(\n",
    "    data_dir=MAESTRO_DATASET_FILEPATH,\n",
    "    split=\"test\",\n",
    "    name=\"maestro_test_base_dataset\",\n",
    "    num_samples=80\n",
    ")\n",
    "print(f\"Obtained {len(ood_base_dataset)} testing examples from Maestro dataset - test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4505700",
   "metadata": {},
   "source": [
    "From each data sample in each of these datasets, extract all sliding windows of length SLIDING_WINDOW_LEN = 120 tokens (=40 events). This can be configured in constants/real_time_constants.py. The stride being STRIDE = 3 corresponds to moving the window by 3 tokens (=1 event) at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96062e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(id_train_dataset) 298822\n",
      "len(id_test_dataset) 500\n",
      "len(ood_dataset) 500\n"
     ]
    }
   ],
   "source": [
    "from constants.real_time_constants import SLIDING_WINDOW_LEN, STRIDE\n",
    "from data.sliding_window import SlidingWindowDataset\n",
    "\n",
    "\n",
    "id_train_dataset = SlidingWindowDataset(id_train_base_dataset, name=\"id_train_dataset\", k=SLIDING_WINDOW_LEN, stride=STRIDE)\n",
    "id_test_dataset = SlidingWindowDataset(id_test_base_dataset, name=\"id_test_dataset\", k=SLIDING_WINDOW_LEN, stride=STRIDE, num_samples=500)\n",
    "ood_dataset = SlidingWindowDataset(ood_base_dataset, name=\"ood_dataset\", k=SLIDING_WINDOW_LEN, stride=STRIDE, num_samples=500)\n",
    "\n",
    "print(\"len(id_train_dataset)\", len(id_train_dataset))\n",
    "print(\"len(id_test_dataset)\", len(id_test_dataset))\n",
    "print(\"len(ood_dataset)\", len(ood_dataset))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d75f5e",
   "metadata": {},
   "source": [
    "### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad9be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from utils.data_loading import collate_fn\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "id_train_dataloader = DataLoader(id_train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "id_test_dataloader = DataLoader(id_test_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "ood_dataloader = DataLoader(ood_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56cff5",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f594f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants.model_constants import DEVICE, JORDAN_MODEL_NAME\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    JORDAN_MODEL_NAME,\n",
    "    dtype=torch.float32,\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d56075",
   "metadata": {},
   "source": [
    "# 2. OOD Detector\n",
    "\n",
    "Refer to [OOD detection docs](../../docs/ood_detection.md) for more information about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b2b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main.transformation_functions import extract_layer_transformation\n",
    "from sklearn.decomposition import PCA\n",
    "from main.transformations import Transformations\n",
    "from main.scoring_functions import k_nearest_neighbors\n",
    "from extract_layers.pooling_functions import pool_mean_std\n",
    "\n",
    "transformations = Transformations(\n",
    "    [\n",
    "        extract_layer_transformation(model, pool_mean_std, [12]),\n",
    "        PCA(n_components=50),\n",
    "    ]\n",
    ")\n",
    "scoring_function = k_nearest_neighbors(k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e4470",
   "metadata": {},
   "source": [
    "## Create OOD detector\n",
    "from transformations and scoring function. Takes about 1 minute with STRIDE=30, lower STRIDE means longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf0f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main.ood_detector import OODDetector\n",
    "\n",
    "ood_detector = OODDetector(\n",
    "    embedding_function=transformations,\n",
    "    scoring_function=scoring_function,\n",
    "    id_train_data=id_train_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3154d9",
   "metadata": {},
   "source": [
    "We can evaluate the detector!\n",
    "\n",
    "```threshold = 0.7``` with ```threshold_type = \"percentile\"``` means that the score threshold is set to be the 70th percentile of all the scores (ID test + OOD test combined)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92690a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix, true_positive_rate, false_positive_rate = ood_detector.evaluate(\n",
    "    id_test_dataloader,\n",
    "    ood_dataloader,\n",
    "    threshold=0.7,\n",
    "    threshold_type=\"percentile\",\n",
    ")\n",
    "print(\"Confusion matrix:\", confusion_matrix)\n",
    "print(\"True positive rate:\", true_positive_rate)\n",
    "print(\"False positive rate:\", false_positive_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98be091",
   "metadata": {},
   "source": [
    "We can plot the ROC curve and get AUROC!\n",
    "\n",
    "AUROC will appear as ```main/auroc.png```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506504ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b92b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.auroc import get_auroc\n",
    "\n",
    "auroc = get_auroc(\n",
    "    ood_detector,\n",
    "    id_test_dataloader,\n",
    "    ood_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUROC:\", auroc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c582ba",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Hover above the bars to see the sample IDs corresponding to the scores. In the next cell, you can input the IDs to hear what the samples sound like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986b9a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.graph_viz import get_graph_visualization\n",
    "\n",
    "fig = get_graph_visualization(\n",
    "    ood_detector,\n",
    "    id_test_dataloader,\n",
    "    ood_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46483e4c",
   "metadata": {},
   "source": [
    "Hear ID input samples and outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99dea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_input_index = 1\n",
    "ood_input_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d2c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.convert import sequence_to_wav\n",
    "from IPython.display import Audio\n",
    "\n",
    "id_input_sample = id_test_dataloader.dataset[id_input_index]\n",
    "id_sequence = id_input_sample[\"input_ids\"].tolist()\n",
    "id_export_filepath = \"id_input_sample.wav\"\n",
    "sequence_to_wav(id_sequence, id_export_filepath)\n",
    "\n",
    "ood_input_sample = ood_dataloader.dataset[ood_input_index]\n",
    "ood_sequence = ood_input_sample[\"input_ids\"]\n",
    "ood_export_filepath = \"ood_input_sample.wav\"\n",
    "sequence_to_wav(ood_sequence, ood_export_filepath)\n",
    "\n",
    "Audio(id_export_filepath)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3278b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(ood_export_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e3ee8e",
   "metadata": {},
   "source": [
    "Hear the outputs from the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9da4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sample import generate_tokens\n",
    "from constants.token_constants import AR\n",
    "\n",
    "generate_length = 120\n",
    "\n",
    "id_output_sample = generate_tokens(\n",
    "    model,\n",
    "    [AR],\n",
    "    id_sequence[1:],\n",
    "    generate_length,\n",
    ")\n",
    "\n",
    "print(\"output\", id_output_sample[len(id_sequence)-1:])\n",
    "\n",
    "id_export_filepath = \"id_ouput_sample.wav\"\n",
    "sequence_to_wav(id_output_sample, id_export_filepath)\n",
    "\n",
    "Audio(id_export_filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5092c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_output_sample = generate_tokens(\n",
    "    model,\n",
    "    [AR],\n",
    "    ood_sequence[1:],\n",
    "    generate_length,\n",
    ")\n",
    "\n",
    "ood_export_filepath = \"ood_output_sample.wav\"\n",
    "sequence_to_wav(ood_output_sample, ood_export_filepath)\n",
    "print(\"output\", ood_output_sample[len(ood_sequence)-1:])\n",
    "\n",
    "Audio(ood_export_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f4b58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ood-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
