{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OOD Detection Results Analysis\n",
        "\n",
        "This notebook loads the results from `stats.json` and displays them sorted by AUROC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the stats.json file\n",
        "stats_file = Path(\"stats.json\")\n",
        "\n",
        "with open(stats_file, \"r\") as f:\n",
        "    stats_data = json.load(f)\n",
        "\n",
        "print(f\"Loaded {len(stats_data)} results\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(stats_data)\n",
        "\n",
        "# Extract confusion matrix values for easier viewing (optional)\n",
        "# The confusion matrix is [[TN, FP], [FN, TP]]\n",
        "df['true_negatives'] = df['confusion_matrix'].apply(lambda x: x[0][0])\n",
        "df['false_positives'] = df['confusion_matrix'].apply(lambda x: x[0][1])\n",
        "df['false_negatives'] = df['confusion_matrix'].apply(lambda x: x[1][0])\n",
        "df['true_positives'] = df['confusion_matrix'].apply(lambda x: x[1][1])\n",
        "\n",
        "# Calculate total samples\n",
        "df['total_samples'] = df['true_negatives'] + df['false_positives'] + df['false_negatives'] + df['true_positives']\n",
        "\n",
        "# Filter rows with at least 100 total samples\n",
        "df = df[df['total_samples'] >= 100].copy()\n",
        "\n",
        "# Sort by AUROC (descending - best first)\n",
        "df_sorted = df.sort_values('auroc', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(f\"Total results: {len(df_sorted)}\")\n",
        "print(f\"\\nBest AUROC: {df_sorted['auroc'].max():.4f}\")\n",
        "print(f\"Worst AUROC: {df_sorted['auroc'].min():.4f}\")\n",
        "print(f\"Mean AUROC: {df_sorted['auroc'].mean():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the full table sorted by AUROC\n",
        "# Select columns to display\n",
        "display_columns = [\n",
        "    'transformations',\n",
        "    'scoring_function',\n",
        "    'auroc',\n",
        "    'true_positive_rate',\n",
        "    'false_positive_rate',\n",
        "    'true_positives',\n",
        "    'true_negatives',\n",
        "    'false_positives',\n",
        "    'false_negatives'\n",
        "]\n",
        "\n",
        "df_display = df_sorted[display_columns].copy()\n",
        "\n",
        "# Format numeric columns for better readability\n",
        "df_display['auroc'] = df_display['auroc'].apply(lambda x: f\"{x:.4f}\")\n",
        "df_display['true_positive_rate'] = df_display['true_positive_rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "df_display['false_positive_rate'] = df_display['false_positive_rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "\n",
        "df_display.to_csv('df_display.csv', index=False)\n",
        "\n",
        "# Display the table\n",
        "df_display\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show top 20 results\n",
        "print(\"Top 20 Results by AUROC:\\n\")\n",
        "df_display.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics by scoring function\n",
        "print(\"Summary by Scoring Function:\\n\")\n",
        "scoring_summary = df_sorted.groupby('scoring_function')['auroc'].agg([\n",
        "    'count', 'mean', 'std', 'min', 'max'\n",
        "]).sort_values('mean', ascending=False)\n",
        "scoring_summary.columns = ['Count', 'Mean AUROC', 'Std AUROC', 'Min AUROC', 'Max AUROC']\n",
        "scoring_summary['Mean AUROC'] = scoring_summary['Mean AUROC'].apply(lambda x: f\"{x:.4f}\")\n",
        "scoring_summary['Std AUROC'] = scoring_summary['Std AUROC'].apply(lambda x: f\"{x:.4f}\")\n",
        "scoring_summary['Min AUROC'] = scoring_summary['Min AUROC'].apply(lambda x: f\"{x:.4f}\")\n",
        "scoring_summary['Max AUROC'] = scoring_summary['Max AUROC'].apply(lambda x: f\"{x:.4f}\")\n",
        "scoring_summary"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ood-detection",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
